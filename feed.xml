<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://kamiaras.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://kamiaras.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-08-10T01:33:36+00:00</updated><id>https://kamiaras.github.io/feed.xml</id><title type="html">Kamy’s Website</title><subtitle>A PhD student&apos;s platform for sharing research and passions. </subtitle><entry><title type="html">Nonsmooth Projection Free Optimization</title><link href="https://kamiaras.github.io/blog/2024/nonsmooth-projection-free-optimization/" rel="alternate" type="text/html" title="Nonsmooth Projection Free Optimization"/><published>2024-02-01T00:00:00+00:00</published><updated>2024-02-01T00:00:00+00:00</updated><id>https://kamiaras.github.io/blog/2024/nonsmooth-projection-free-optimization</id><content type="html" xml:base="https://kamiaras.github.io/blog/2024/nonsmooth-projection-free-optimization/"><![CDATA[<p>layout: post title: Nonsmooth Projection-Free Optimization date: 2024-02-01 00:00:00 description: Convex, L-Lipschitz objectives via a projection-free primal–dual saddle formulation and optimistic OMD. tags: optimization convex nonsmooth frank-wolfe saddle-point omd lipschitz categories: research-notes redirect: /assets/pdf/Projection-Free.pdf</p> <p><strong>Author:</strong> Kamiar</p> <hr/> <h2 id="setup">Setup</h2> <p>[ \min_{x\in\mathcal{X}} f(x). ]</p> <p>\(\min_{x\in\mathcal{X}} f(x).\) Let $\mathcal{X}\subseteq\mathbb{R}^n$ be nonempty, compact, and convex with diameter $D_{\mathcal X}$. Let $\mathcal{Y}\subseteq\mathbb{R}^n$ be closed and convex with $\mathcal{X}\subseteq\mathcal{Y}$; if $\mathcal{Y}$ is bounded, denote its diameter by $D_{\mathcal Y}$. Let $f:\mathcal{Y}\to\mathbb{R}$ be convex and $L$-Lipschitz (w.r.t. $|\cdot|$), i.e., $|g|\le L$ for all $g\in \partial f(y)$ and $y\in\mathcal{Y}$.</p> <p><strong>(P1)</strong></p> \[\min_{x\in\mathcal{X}} f(x).\] <p>Introduce a copy variable $y\in\mathcal{Y}$:</p> <p><strong>(P1.2)</strong></p> \[\min_{x\in\mathcal{X},\,y\in\mathcal{Y}} f(y)\quad \text{s.t.}\quad x=y.\] <p><strong>Lemma (Exact penalty via Lipschitzness).</strong> For any $L$-Lipschitz convex $f$,</p> <p><strong>(P2)</strong></p> \[\min_{x\in\mathcal{X},\,y\in\mathcal{Y}} f(y)+L\|y-x\| \;=\; \min_{x\in\mathcal{X}} f(x).\] <p><em>Proof.</em> For any $x,y$, $f(x)\le f(y)+L|x-y|$, hence the RHS is $\le$ the LHS. Taking $y=x\in\arg\min_{x\in\mathcal{X}} f(x)$ gives equality. □</p> <p>Using the indicator $\delta_{\mathcal{X}}(x)=0$ if $x\in\mathcal{X}$ and $+\infty$ otherwise, (P2) becomes</p> \[\min_{x\in\mathbb{R}^n,\,y\in\mathcal{Y}} f(y)+\delta_{\mathcal{X}}(x)+L\|y-x\|.\] <p>Fenchel representations:</p> \[\delta_{\mathcal{X}}(x)=\sup_{q\in\mathbb{R}^n}\, \langle q, x\rangle-\sigma_{\mathcal{X}}(q), \qquad \|z\|=\sup_{p\in\mathbb{R}^n}\, \langle p, z\rangle-\delta_{\mathcal{B}^*_1}(p),\] <p>where $\sigma_{\mathcal{X}}(q)=\sup_{x\in\mathcal{X}}\langle q,x\rangle$ is the support function and $\mathcal{B}^<em>_r={p:|p|^</em>\le r}$ is the dual-norm ball of radius $r$.</p> <p>Substituting yields a saddle problem:</p> \[\min_{x\in\mathbb{R}^n,\,y\in\mathcal{Y}}\;\max_{q\in\mathbb{R}^n,\,p\in\mathbb{R}^n}\; f(y) + \langle q,x\rangle - \sigma_{\mathcal{X}}(q) + L\langle p, y-x\rangle - L\,\delta_{\mathcal{B}^*_1}(p).\] <p>Minimizing over $x$ enforces $q=Lp$; eliminating $p$ gives $q\in \mathcal{B}^*_L$. Hence:</p> <p><strong>(SP)</strong></p> \[\min_{y\in\mathcal{Y}}\;\max_{q\in \mathcal{B}^*_L}\; f(y) + \langle q, y\rangle - \sigma_{\mathcal{X}}(q).\] <p><strong>Support points.</strong> For $q\in\mathbb{R}^n$, let $s_{\mathcal{X}}(q)\in\arg\max_{x\in\mathcal{X}}\langle q,x\rangle$ be any <em>support point</em> (a subgradient of $\sigma_{\mathcal{X}}$ at $q$). Then $\langle q, s_{\mathcal{X}}(q)-x\rangle\ge 0$ for all $x\in\mathcal{X}$.</p> <hr/> <h2 id="algorithm-1--basic-primaldual-scheme-euclidean-case">Algorithm 1 — Basic primal–dual scheme (Euclidean case)</h2> <p>Assume $|\cdot|=|\cdot|_2$. With stepsizes $\eta,\alpha&gt;0$ and subgradients $g_t\in\partial f(y_t)$,</p> \[y_{t+1} = \arg\min_{y\in\mathcal{Y}} \; \langle g_t+q_t,\,y\rangle+\tfrac{\eta}{2}\|y-y_t\|_2^2,\] \[q_{t+1} = \arg\min_{q\in \mathcal{B}^*_L}\; \langle q,\,s_{\mathcal{X}}(q_t)-y_t\rangle+\tfrac{\alpha}{2}\|q-q_t\|_2^2.\] <p><em>Note.</em> One may drop the explicit constraint $q\in \mathcal{B}^*_L$ if regularization implicitly keeps $q_t$ bounded.</p> <h3 id="analysis-sketch">Analysis (Sketch)</h3> <p>For any $x_<em>\in\mathcal{X}$ and $q_</em>\in \mathcal{B}^*_L$,</p> \[\sum_{t=1}^T\langle g_t, y_t-x_*\rangle + \sum_{t=1}^T \langle q_*, y_t-s_{\mathcal{X}}(q_t)\rangle \le \frac{T L^2}{\eta}+\frac{\eta D_{\mathcal X}^2}{2} +\frac{T D_{\mathcal Y}^2}{2\alpha}+\frac{\alpha L^2}{2}.\] <p>With $\bar y_T=\tfrac1T\sum_{t=1}^T y_t$, $\bar x_T=\tfrac1T\sum_{t=1}^T s_{\mathcal{X}}(q_t)$, and $q_<em>\in\partial f(\bar x_T)$ ($|q_</em>|\le L$),</p> \[f(\bar x_T)-f(x_*) \le \frac{L^2}{\eta} +\frac{\eta D_{\mathcal X}^2}{2T} +\frac{D_{\mathcal Y}^2}{2\alpha} +\frac{\alpha L^2}{2T}.\] <p><strong>Corollary (Rate for Algorithm 1).</strong> With $\eta=\sqrt{2}\,L\sqrt{T}/D_{\mathcal X}$ and $\alpha=\sqrt{T}\,D_{\mathcal Y}/L$,</p> \[f(\bar x_T)-f(x_*) \le \frac{(\sqrt{2}\,D_{\mathcal X} + D_{\mathcal Y})\,L}{\sqrt{T}}.\] <hr/> <h2 id="algorithm-2--replace-d_mathcal-y-by-d_mathcal-x-via-optimistic-omd">Algorithm 2 — Replace $D_{\mathcal Y}$ by $D_{\mathcal X}$ via optimistic OMD</h2> <p>Initialize $y_0\in\mathcal{X}$, set $q_0=0$ so that $s_{\mathcal{X}}(q_0)=y_0$, and take $q_1=q_0$, $y_1=y_0$. For $t\ge 1$, with $g_t\in\partial f(y_t)$,</p> \[y_{t+1} = \arg\min_{y\in\mathcal{Y}} \; \langle g_t+q_t,\,y\rangle+\tfrac{\eta}{2}\|y-y_t\|_2^2,\] \[q_{t+1} = \arg\min_{q\in \mathcal{B}^*_L}\; \left\langle q,\;2s_{\mathcal{X}}(q_t)-s_{\mathcal{X}}(q_{t-1})-y_{t+1}\right\rangle +\tfrac{\alpha}{2}\|q-q_t\|_2^2.\] <p>This is an <em>optimistic</em> OMD step for $g^{(q)}<em>t := s</em>{\mathcal{X}}(q_t)-y_t$ with prediction $\tilde g^{(q)}<em>t := s</em>{\mathcal{X}}(q_{t-1})-y_t$.</p> <h3 id="analysis-sketch-1">Analysis (Sketch)</h3> <p>For any $q_<em>\in\mathcal{B}^</em>_L$,</p> \[\sum_{t=1}^T \langle q_t-q_*,\,s_{\mathcal{X}}(q_t)-y_t\rangle \le \sum_{t=1}^T \frac{\|s_{\mathcal{X}}(q_t)-s_{\mathcal{X}}(q_{t-1})\|_2^2}{2\alpha} +\frac{\alpha}{2}\|q_*-q_1\|_2^2.\] <p>Since $s_{\mathcal{X}}(q_t)\in\mathcal{X}$ and $q_1=0$,</p> \[\sum_{t=1}^T \langle q_t-q_*,\,s_{\mathcal{X}}(q_t)-y_t\rangle \le \frac{T\,D_{\mathcal X}^2}{2\alpha} + \frac{\alpha L^2}{2}.\] <p>Combining with the $y$-update bound (using $D_{\mathcal X}$ for both telescoping terms),</p> \[f(\bar x_T)-f(x_*) \le \frac{L^2}{\eta} +\frac{\eta D_{\mathcal X}^2}{2T} +\frac{D_{\mathcal X}^2}{2\alpha} +\frac{\alpha L^2}{2T}.\] <p><strong>Corollary (Rate for Algorithm 2).</strong> With $\eta=\sqrt{2}\,L\sqrt{T}/D_{\mathcal X}$ and $\alpha=\sqrt{T}\,D_{\mathcal X}/L$,</p> \[f(\bar x_T)-f(x_*) \le \frac{(\sqrt{2}+1)\,L\,D_{\mathcal X}}{\sqrt{T}}.\] <p><strong>Remark (Oracle model).</strong> The update $s_{\mathcal{X}}(q_t)\in\arg\max_{x\in\mathcal{X}}\langle q_t,x\rangle$ is a linear minimization oracle (LMO) as in Frank–Wolfe, so the scheme is projection-free on $\mathcal{X}$.</p> <hr/> <h2 id="references">References</h2> <ul> <li>Orabona, F. (2023). <em>A Modern Introduction to Online Learning</em>. arXiv preprint.</li> </ul>]]></content><author><name></name></author><summary type="html"><![CDATA[layout: post title: Nonsmooth Projection-Free Optimization date: 2024-02-01 00:00:00 description: Convex, L-Lipschitz objectives via a projection-free primal–dual saddle formulation and optimistic OMD. tags: optimization convex nonsmooth frank-wolfe saddle-point omd lipschitz categories: research-notes redirect: /assets/pdf/Projection-Free.pdf]]></summary></entry><entry><title type="html">Formatting And Links</title><link href="https://kamiaras.github.io/blog/2015/formatting-and-links/" rel="alternate" type="text/html" title="Formatting And Links"/><published>2015-03-15T00:00:00+00:00</published><updated>2015-03-15T00:00:00+00:00</updated><id>https://kamiaras.github.io/blog/2015/formatting-and-links</id><content type="html" xml:base="https://kamiaras.github.io/blog/2015/formatting-and-links/"><![CDATA[<p>layout: post title: a post with formatting and links date: 2015-03-15 16:40:16 description: march &amp; april, looking forward to summer tags: formatting links categories: sample-posts Jean shorts raw denim Vice normcore, art party High Life PBR skateboard stumptown vinyl kitsch. Four loko meh 8-bit, tousled banh mi tilde forage Schlitz dreamcatcher twee 3 wolf moon. Chambray asymmetrical paleo salvia, sartorial umami four loko master cleanse drinking vinegar brunch. <a href="https://www.pinterest.com">Pinterest</a> DIY authentic Schlitz, hoodie Intelligentsia butcher trust fund brunch shabby chic Kickstarter forage flexitarian. Direct trade <a href="https://en.wikipedia.org/wiki/Cold-pressed_juice">cold-pressed</a> meggings stumptown plaid, pop-up taxidermy. Hoodie XOXO fingerstache scenester Echo Park. Plaid ugh Wes Anderson, freegan pug selvage fanny pack leggings pickled food truck DIY irony Banksy.</p> <h4 id="hipster-list">Hipster list</h4> <ul> <li>brunch</li> <li>fixie</li> <li>raybans</li> <li>messenger bag</li> </ul> <p>Hoodie Thundercats retro, tote bag 8-bit Godard craft beer gastropub. Truffaut Tumblr taxidermy, raw denim Kickstarter sartorial dreamcatcher. Quinoa chambray slow-carb salvia readymade, bicycle rights 90’s yr typewriter selfies letterpress cardigan vegan.</p> <hr/> <p>Pug heirloom High Life vinyl swag, single-origin coffee four dollar toast taxidermy reprehenderit fap distillery master cleanse locavore. Est anim sapiente leggings Brooklyn ea. Thundercats locavore excepteur veniam eiusmod. Raw denim Truffaut Schlitz, migas sapiente Portland VHS twee Bushwick Marfa typewriter retro id keytar.</p> <blockquote> We do not grow absolutely, chronologically. We grow sometimes in one dimension, and not in another, unevenly. We grow partially. We are relative. We are mature in one realm, childish in another. —Anais Nin </blockquote> <p>Fap aliqua qui, scenester pug Echo Park polaroid irony shabby chic ex cardigan church-key Odd Future accusamus. Blog stumptown sartorial squid, gastropub duis aesthetic Truffaut vero. Pinterest tilde twee, odio mumblecore jean shorts lumbersexual.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[layout: post title: a post with formatting and links date: 2015-03-15 16:40:16 description: march &amp; april, looking forward to summer tags: formatting links categories: sample-posts Jean shorts raw denim Vice normcore, art party High Life PBR skateboard stumptown vinyl kitsch. Four loko meh 8-bit, tousled banh mi tilde forage Schlitz dreamcatcher twee 3 wolf moon. Chambray asymmetrical paleo salvia, sartorial umami four loko master cleanse drinking vinegar brunch. Pinterest DIY authentic Schlitz, hoodie Intelligentsia butcher trust fund brunch shabby chic Kickstarter forage flexitarian. Direct trade cold-pressed meggings stumptown plaid, pop-up taxidermy. Hoodie XOXO fingerstache scenester Echo Park. Plaid ugh Wes Anderson, freegan pug selvage fanny pack leggings pickled food truck DIY irony Banksy.]]></summary></entry></feed>